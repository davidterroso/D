{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a595fa70",
   "metadata": {},
   "source": [
    "# Test in Centro Hospitalar Universitário de São João's (CHUSP) Dataset\n",
    "\n",
    "### Using the models from **Run076** (IRF), **Run111** (SRF), and **Run114** (PED) in Binary Implementation and model from **Run058** in Multi-class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ba622",
   "metadata": {},
   "source": [
    "### Multi-class Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359a1e0",
   "metadata": {},
   "source": [
    "#### Resized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a466719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_model import test_model\n",
    "\n",
    "test_model(\n",
    "    fold_test=1,\n",
    "    model_name=\"UNet\",\n",
    "    weights_name=\"Run058_UNet_best_model.pth\",\n",
    "    number_of_channels=1,\n",
    "    number_of_classes=4,\n",
    "    dataset=\"chusj\",\n",
    "    device_name=\"GPU\",\n",
    "    batch_size=1,\n",
    "    patch_type=\"vertical\",\n",
    "    save_images=True,\n",
    "    resize_images=True,\n",
    "    final_test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d55b85e",
   "metadata": {},
   "source": [
    "#### Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_model import test_model\n",
    "\n",
    "test_model(\n",
    "    fold_test=1,\n",
    "    model_name=\"UNet\",\n",
    "    weights_name=\"Run058_UNet_best_model.pth\",\n",
    "    number_of_channels=1,\n",
    "    number_of_classes=4,\n",
    "    dataset=\"chusj\",\n",
    "    device_name=\"GPU\",\n",
    "    batch_size=1,\n",
    "    patch_type=\"vertical\",\n",
    "    save_images=True,\n",
    "    resize_images=False,\n",
    "    final_test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe5466",
   "metadata": {},
   "source": [
    "### Binary Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b48fd8",
   "metadata": {},
   "source": [
    "#### Resized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_model import test_model\n",
    "\n",
    "test_model(\n",
    "    fold_test=1,\n",
    "    model_name=\"UNet3\",\n",
    "    weights_name=\"Run076111114_UNet3\",\n",
    "    number_of_channels=1,\n",
    "    number_of_classes=2,\n",
    "    dataset=\"chusj\",\n",
    "    device_name=\"GPU\",\n",
    "    batch_size=1,\n",
    "    patch_type=\"vertical\",\n",
    "    save_images=True,\n",
    "    resize_images=True,\n",
    "    final_test=True,\n",
    "    selected_models=[76,111,114],\n",
    "    mode='highest_prob'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066b6de",
   "metadata": {},
   "source": [
    "#### Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_model import test_model\n",
    "\n",
    "test_model(\n",
    "    fold_test=1,\n",
    "    model_name=\"UNet3\",\n",
    "    weights_name=\"Run076111114_UNet3\",\n",
    "    number_of_channels=1,\n",
    "    number_of_classes=2,\n",
    "    dataset=\"chusj\",\n",
    "    device_name=\"GPU\",\n",
    "    batch_size=1,\n",
    "    patch_type=\"vertical\",\n",
    "    save_images=True,\n",
    "    resize_images=False,\n",
    "    final_test=True,\n",
    "    selected_models=[76,111,114],\n",
    "    mode='highest_prob'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c8c34",
   "metadata": {},
   "source": [
    "### Calculate Dice - Processed Images\n",
    "\n",
    "The Dice coefficient is calculated for the same slices after being processed. The path to the processed images is informed the results are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f1f5a",
   "metadata": {},
   "source": [
    "Declare the path to the processed images below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_folder = \"\"\n",
    "resized = True\n",
    "binary = False\n",
    "\n",
    "\n",
    "if binary:\n",
    "    run_name = \"Run076111114\"\n",
    "else:\n",
    "    run_name = \"Run058\"\n",
    "\n",
    "if resized:\n",
    "    gt_masks_folder = \"D:\\DavidTerroso\\Images\\OCT_images\\chusj\\masks_resized\"\n",
    "    oct_folder = \"D:\\DavidTerroso\\Images\\OCT_images\\chusj\\slices_resized\" \n",
    "else:\n",
    "    gt_masks_folder = \"D:\\DavidTerroso\\Images\\OCT_images\\chusj\\masks\"\n",
    "    oct_folder = \"D:\\DavidTerroso\\Images\\OCT_images\\chusj\\slices\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from os import listdir, makedirs\n",
    "from os.path import exists\n",
    "from pandas import DataFrame, Series\n",
    "from shutil import rmtree\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from networks.loss import dice_coefficient\n",
    "from paths import IMAGES_PATH\n",
    "\n",
    "slice_results = []\n",
    "\n",
    "# Dictionary of labels in masks to fluid names\n",
    "label_to_fluids = {\n",
    "    0: \"Background\",\n",
    "    1: \"IRF\",\n",
    "    2: \"SRF\",\n",
    "    3: \"PED\"\n",
    "}\n",
    "\n",
    "# Dictionary of fluid to labels in masks\n",
    "fluids_to_label = {\n",
    "    \"IRF\": 1,\n",
    "    \"SRF\": 2,\n",
    "    \"PED\": 3\n",
    "} \n",
    "\n",
    "if not resized: \n",
    "    folder_to_save = IMAGES_PATH + f\"\\\\OCT_images\\\\segmentation\\\\predictions\\\\{run_name}_final_processed_chusj\\\\\"\n",
    "    folder_to_save_masks = IMAGES_PATH + f\"\\\\OCT_images\\\\segmentation\\\\predictions\\\\{run_name}_final_processed_chusj_masks\\\\\"\n",
    "    folder_to_save_gts = IMAGES_PATH + f\"\\\\OCT_images\\\\segmentation\\\\predictions\\\\{run_name}_final_processed_chusj_gts\\\\\"\n",
    "\n",
    "else:\n",
    "    folder_to_save = IMAGES_PATH + f\"\\\\OCT_images\\\\segmentation\\\\predictions\\\\{run_name}_resized_final_processed_chusj\\\\\"\n",
    "    folder_to_save_masks = IMAGES_PATH + f\"\\\\OCT_images\\\\segmentation\\\\predictions\\\\{run_name}_resized_final_processed_chusj\\\\\"\n",
    "    folder_to_save_gts = IMAGES_PATH + f\"\\\\OCT_images\\\\segmentation\\\\predictions\\\\{run_name}_resized_final_processed_chusj_gts\\\\\"\n",
    "    \n",
    "    # In case the folder to save exists, it is deleted and created again\n",
    "    if exists(folder_to_save):\n",
    "        rmtree(folder_to_save)\n",
    "        makedirs(folder_to_save)\n",
    "    else:\n",
    "        makedirs(folder_to_save)\n",
    "    if exists(folder_to_save_masks):\n",
    "        rmtree(folder_to_save_masks)\n",
    "        makedirs(folder_to_save_masks)\n",
    "    else:\n",
    "        makedirs(folder_to_save_masks)\n",
    "    if exists(folder_to_save_gts):\n",
    "        rmtree(folder_to_save_gts)\n",
    "        makedirs(folder_to_save_gts)\n",
    "    else:\n",
    "        makedirs(folder_to_save_gts)\n",
    "\n",
    "\n",
    "with tqdm(listdir(processed_folder), total=len(listdir(processed_folder)), desc='Testing Model', unit='img', leave=True, position=0) as progress_bar:\n",
    "    for img_path in listdir(processed_folder):\n",
    "        image_name = img_path.split(\"\\\\\")[-1][:-5]\n",
    "        oct_image = imread(str(oct_folder + \"\\\\\" + image_name + \".tiff\"))\n",
    "        pred = torch.from_numpy(imread(img_path))\n",
    "        gt = torch.from_numpy(imread(str(gt_masks_folder + \"\\\\\" + image_name + \"_predicted.tiff\")))\n",
    "        dice_scores, voxel_counts, union_counts, intersection_counts, binary_dice = dice_coefficient(model_name=\"UNet\", target=gt, prediction=pred, num_classes=4)\n",
    "        slice_results.append([image_name, *dice_scores, *voxel_counts, *union_counts, *intersection_counts, binary_dice])\n",
    "\n",
    "        # Declares the name under which the masks will be saved and writes the path to the original B-scan\n",
    "        predicted_mask_name = folder_to_save + image_name + \"_predicted.tiff\"\n",
    "\n",
    "        # Saves the segmentation masks\n",
    "        pred = np.array(pred.cpu().numpy(), dtype=np.float32)[0]\n",
    "\n",
    "        # Converts each voxel classified as background to \n",
    "        # NaN so that it will not appear in the overlaying\n",
    "        # mask\n",
    "        pred[pred == 0] = np.nan\n",
    "\n",
    "        # The voxels classified in \"IRF\", \"SRF\", and \"PED\" \n",
    "        # will be converted to color as Red for IRF, green \n",
    "        # for SRF, and blue for PED\n",
    "        fluid_colors = [\"red\", \"green\", \"blue\"]\n",
    "        fluid_cmap = mcolors.ListedColormap(fluid_colors)\n",
    "        # Declares in which part of the color bar each\n",
    "        # label is going to be placed\n",
    "        fluid_bounds = [1, 2, 3, 4]\n",
    "        # Normalizes the color map according to the \n",
    "        # bounds declared.\n",
    "        fluid_norm = mcolors.BoundaryNorm(fluid_bounds, fluid_cmap.N)\n",
    "\n",
    "        # Saves the OCT scan with an overlay of the predicted masks\n",
    "        plt.figure(figsize=(oct_image.shape[1] / 100, oct_image.shape[0] / 100))\n",
    "        plt.imshow(oct_image, cmap=plt.cm.gray)\n",
    "        plt.imshow(pred, alpha=0.3, cmap=fluid_cmap, norm=fluid_norm)\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(predicted_mask_name, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "        # Closes the figure\n",
    "        plt.clf()\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "slice_df = DataFrame(slice_results, \n",
    "                    columns=[\"slice\", \n",
    "                            *[f\"dice_{label_to_fluids.get(i)}\" for i in range(4)], \n",
    "                            *[f\"voxels_{label_to_fluids.get(i)}\" for i in range(4)], \n",
    "                            *[f\"union_{label_to_fluids.get(i)}\" for i in range(4)], \n",
    "                            *[f\"intersection_{label_to_fluids.get(i)}\" for i in range(4)],\n",
    "                            \"binary_dice\"])\n",
    "if not resized:\n",
    "    slice_df.to_csv(f\"results/{run_name}_slice_dice_final_processed_chusj.csv\", index=False)\n",
    "else:\n",
    "    slice_df.to_csv(f\"results/{run_name}_slice_dice_resized_final_processed_chusj.csv\", index=False)\n",
    "\n",
    "# Adds the vendor, volume, and number of the slice information to the DataFrame\n",
    "slice_df[['vendor', 'volume', 'slice_number']] = slice_df['slice'].str.replace('.tiff', '', regex=True).str.split('_', n=2, expand=True)\n",
    "# Saves the DataFrame with the mean and standard deviation for each OCT volume (e.g. mean (standard deviation))\n",
    "volume_df_mean = slice_df[[\"volume\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"volume\").mean()\n",
    "volume_df_mean.index.name = \"Volume\"\n",
    "volume_df_std = slice_df[[\"volume\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"volume\").std()\n",
    "volume_df_std.index.name = \"Volume\"\n",
    "resulting_volume_df = volume_df_mean.astype(str) + \" (\" + volume_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame with the mean and standard deviation for each vendor (e.g. mean (standard deviation))\n",
    "vendor_df_mean = slice_df[[\"vendor\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"vendor\").mean()\n",
    "vendor_df_mean.index.name = \"Vendor\"\n",
    "vendor_df_std = slice_df[[\"vendor\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"vendor\").std()\n",
    "vendor_df_std.index.name = \"Vendor\"\n",
    "resulting_vendor_df = vendor_df_mean.astype(str) + \" (\" + vendor_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame with the mean and standard deviation for each class (e.g. mean (standard deviation))\n",
    "class_df_mean = slice_df[[\"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].mean().to_frame().T\n",
    "class_df_std = slice_df[[\"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].std().to_frame().T\n",
    "resulting_class_df = class_df_mean.astype(str) + \" (\" + class_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame that contains the values for each volume, class, and vendor\n",
    "if not resized:\n",
    "    resulting_volume_df.to_csv(f\"results/{run_name}_volume_dice_final_chusj.csv\", index=True)\n",
    "    resulting_class_df.to_csv(f\"results/{run_name}_class_dice_final_chusj.csv\", index=False)\n",
    "    resulting_vendor_df.to_csv(f\"results/{run_name}_vendor_dice_final_chusj.csv\", index=True)            \n",
    "else:\n",
    "    resulting_volume_df.to_csv(f\"results/{run_name}_volume_dice_resized_final_chusj.csv\", index=True)\n",
    "    resulting_class_df.to_csv(f\"results/{run_name}_class_dice_resized_final_chusj.csv\", index=False)\n",
    "    resulting_vendor_df.to_csv(f\"results/{run_name}_vendor_dice_resized_final_chusj.csv\", index=True)\n",
    "\n",
    "# Handles the information only on the slices that have the fluid\n",
    "slice_df_wf = slice_df.copy()\n",
    "# Iterates through all the classes available\n",
    "for i in range(4):\n",
    "    # Sets the Dice values to NaN whenever there is no fluid of that type\n",
    "    slice_df_wf.loc[slice_df_wf[f\"voxels_{label_to_fluids.get(i)}\"] == 0, f\"dice_{label_to_fluids.get(i)}\"] = np.nan\n",
    "\n",
    "# Adds the vendor, volume, and number of the slice information to the DataFrame\n",
    "slice_df_wf[['vendor', 'volume', 'slice_number']] = slice_df_wf['slice'].str.replace('.tiff', '', regex=True).str.split('_', n=2, expand=True)\n",
    "# Saves the DataFrame with the mean and standard deviation for each OCT volume (e.g. mean (standard deviation))\n",
    "volume_df_mean = slice_df_wf[[\"volume\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"volume\").mean()\n",
    "volume_df_mean.index.name = \"Volume\"\n",
    "volume_df_std = slice_df_wf[[\"volume\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"volume\").std()\n",
    "volume_df_std.index.name = \"Volume\"\n",
    "resulting_volume_df = volume_df_mean.astype(str) + \" (\" + volume_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame with the mean and standard deviation for each vendor (e.g. mean (standard deviation))\n",
    "vendor_df_mean = slice_df_wf[[\"vendor\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"vendor\").mean()\n",
    "vendor_df_mean.index.name = \"Vendor\"\n",
    "vendor_df_std = slice_df_wf[[\"vendor\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"vendor\").std()\n",
    "vendor_df_std.index.name = \"Vendor\"\n",
    "resulting_vendor_df = vendor_df_mean.astype(str) + \" (\" + vendor_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame with the mean and standard deviation for each class (e.g. mean (standard deviation))\n",
    "class_df_mean = slice_df_wf[[\"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].mean().to_frame().T\n",
    "class_df_std = slice_df_wf[[\"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].std().to_frame().T\n",
    "resulting_class_df = class_df_mean.astype(str) + \" (\" + class_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame that contains the values for each volume, class, and vendor\n",
    "if not resized:\n",
    "    resulting_volume_df.to_csv(f\"results/{run_name}_volume_dice_wfluid_final_processed_chusj.csv\", index=True)\n",
    "    resulting_class_df.to_csv(f\"results/{run_name}_class_dice_wfluid_final_processed_chusj.csv\", index=False)\n",
    "    resulting_vendor_df.to_csv(f\"results/{run_name}_vendor_dice_wfluid_final_processed_chusj.csv\", index=True)\n",
    "else:\n",
    "    resulting_volume_df.to_csv(f\"results/{run_name}_volume_dice_resized_wfluid_final_processed_chusj.csv\", index=True)\n",
    "    resulting_class_df.to_csv(f\"results/{run_name}_class_dice_resized_wfluid_final_processed_chusj.csv\", index=False)\n",
    "    resulting_vendor_df.to_csv(f\"results/{run_name}_vendor_dice_resized_wfluid_final_processed_chusj.csv\", index=True)\n",
    "\n",
    "# Handles the information only on the slices that do not have fluid\n",
    "slice_df_wof = slice_df.copy()\n",
    "# Iterates through all the classes available\n",
    "for i in range(4):\n",
    "    # Gets the DataFrame that contains a non-negative number of voxels for each column\n",
    "    slice_df_wof.loc[slice_df_wof[f\"voxels_{label_to_fluids.get(i)}\"] > 0, f\"dice_{label_to_fluids.get(i)}\"] = np.nan\n",
    "\n",
    "# Adds the vendor, volume, and number of the slice information to the DataFrame\n",
    "slice_df_wof[['vendor', 'volume', 'slice_number']] = slice_df_wof['slice'].str.replace('.tiff', '', regex=True).str.split('_', n=2, expand=True)\n",
    "# Saves the DataFrame with the mean and standard deviation for each OCT volume (e.g. mean (standard deviation))\n",
    "volume_df_mean = slice_df_wof[[\"volume\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"volume\").mean()\n",
    "volume_df_mean.index.name = \"Volume\"\n",
    "volume_df_std = slice_df_wof[[\"volume\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"volume\").std()\n",
    "volume_df_std.index.name = \"Volume\"\n",
    "resulting_volume_df = volume_df_mean.astype(str) + \" (\" + volume_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame with the mean and standard deviation for each vendor (e.g. mean (standard deviation))\n",
    "vendor_df_mean = slice_df_wof[[\"vendor\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"vendor\").mean()\n",
    "vendor_df_mean.index.name = \"Vendor\"\n",
    "vendor_df_std = slice_df_wof[[\"vendor\", \"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].groupby(\"vendor\").std()\n",
    "vendor_df_std.index.name = \"Vendor\"\n",
    "resulting_vendor_df = vendor_df_mean.astype(str) + \" (\" + vendor_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame with the mean and standard deviation for each class (e.g. mean (standard deviation))\n",
    "class_df_mean = slice_df_wof[[\"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].mean().to_frame().T\n",
    "class_df_std = slice_df_wof[[\"dice_IRF\", \"dice_SRF\", \"dice_PED\"]].std().to_frame().T\n",
    "resulting_class_df = class_df_mean.astype(str) + \" (\" + class_df_std.astype(str) + \")\"\n",
    "\n",
    "# Saves the DataFrame that contains the values for each volume, class, and vendor\n",
    "if not resized:\n",
    "    resulting_volume_df.to_csv(f\"results/{run_name}_volume_dice_wofluid_final_processed_chusj.csv\", index=True)\n",
    "    resulting_class_df.to_csv(f\"results/{run_name}_class_dice_wofluid_final_processed_chusj.csv\", index=False)\n",
    "    resulting_vendor_df.to_csv(f\"results/{run_name}_vendor_dice_wofluid_final_processed_chusj.csv\", index=True)\n",
    "    binary_dices_name = f\"fluid_dice_final__processed_chusj\"\n",
    "else:\n",
    "    resulting_volume_df.to_csv(f\"results/{run_name}_volume_dice_resized_wofluid_final_processed_chusj.csv\", index=True)\n",
    "    resulting_class_df.to_csv(f\"results/{run_name}_class_dice_resized_wofluid_final_processed_chusj.csv\", index=False)\n",
    "    resulting_vendor_df.to_csv(f\"results/{run_name}_vendor_dice_resized_wofluid_final_processed_chusj.csv\", index=True)\n",
    "    binary_dices_name = f\"fluid_dice_resized_final_processed_chusj\"\n",
    "\n",
    "# Initializes a list that will hold the results for the binary case\n",
    "binary_dices = []\n",
    "# Appends the binary Dice coefficient to a list that holds these values\n",
    "binary_dices.append(f\"{slice_df['binary_dice'].mean()} ({slice_df['binary_dice'].std()})\")\n",
    "\n",
    "# Get the fluid voxel column names (i = 1, 2, 3)\n",
    "fluid_voxel_cols = [f\"voxels_{label_to_fluids[i]}\" for i in [1, 2, 3]]\n",
    "\n",
    "# Copies the original DataFrame \n",
    "# on which changes will be applied\n",
    "slice_df_wf = slice_df.copy()\n",
    "slice_df_wof = slice_df.copy()\n",
    "\n",
    "# For the 'with fluid' DataFrame, the slices with no fluid will be set to NaN in the \n",
    "# column that contains the binary Dice        \n",
    "slice_df_wf.loc[slice_df_wf[fluid_voxel_cols].sum(axis=1) == 0, 'binary_dice'] = np.nan\n",
    "\n",
    "# For the 'without fluid' DataFrame, the slices with any fluid will be set to NaN in the \n",
    "# column that contains the binary Dice\n",
    "slice_df_wof.loc[slice_df_wof[fluid_voxel_cols].sum(axis=1) > 0, 'binary_dice'] = np.nan\n",
    "\n",
    "# The mean and std of each column is added to a list that contains the results in binary conditions\n",
    "binary_dices.append(f\"{slice_df_wf['binary_dice'].mean()} ({slice_df_wf['binary_dice'].std()})\")\n",
    "binary_dices.append(f\"{slice_df_wof['binary_dice'].mean()} ({slice_df_wof['binary_dice'].std()})\")\n",
    "\n",
    "# Saves the results as a DataFrame\n",
    "df = Series(binary_dices).to_frame().T\n",
    "df.columns = [\"AllSlices\", \"SlicesWithFluid\", \"SlicesWithoutFluid\"]\n",
    "df.to_csv(f\"results/{run_name}_{binary_dices_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
