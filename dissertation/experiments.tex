\chapter{Experiments}\label{Experiments}
Building upon the methods and materials exposed, the experiments conducted during this dissertation are explained in depth in this chapter. It begins with a description of how the data were split, followed by the experiments on fluid segmentation, intermediate slice generation, and fluid volume estimation.
\par
All experiments were conducted using an NVIDIA GeForce RTX 3080 GPU and the \hbox{PyTorch} machine learning library (version 2.5.1).

\section{Data Partition}\label{CrossValidation}
To promote consistency across all experiments, the conditions were held identical. In every experiment, the data were split into five folds, with different splits being used for the segmentation and generation tasks. From these five folds, one was reserved until the end to compare the performance of the models trained in the different experiments and identify the one that generalizes best to an unseen image set. The remaining four folds were used for training the models through a 4-fold cross-validation procedure, in which three folds were used for training and one for validation. Therefore, four training runs are completed in each experiment, rotating the validation fold across runs. The reserved fold consists of the same OCT volumes for all experiments, allowing for further comparisons on data not seen by any of the models. Fold 1 was randomly selected as the reserved fold.
\par
For the multi-class segmentation models, the data were split so that the quantity of each fluid and the number of volumes per vendor were evenly distributed across the folds - referred to as a multi-class 5-fold split. This balanced distribution allows for a fairer assessment of the model's learning ability and its performance on data with varying characteristics (e.g., from different vendors). To achieve this, a custom algorithm was developed to divide the data into five folds while minimizing discrepancies in fluid distribution and the number of slices per vendor within each fold.
\par
A possible distribution of the 70 OCT volumes from the RETOUCH dataset, which were used in the training of the fluid segmentation models, can be seen in Table \ref{tab:FiveFoldSplit}. The split was applied to the volumes and not to the slices. Slices from the same volume must be kept together to prevent data leakage, where similar images obtained from the same patient appear in both the training and validation sets, potentially resulting in overly optimistic performance metrics.

\begin{table*}[!ht]
	\setlength{\tabcolsep}{6pt}
	\renewcommand{\arraystretch}{1.3}
	\caption{Number of OCT volumes per vendor in each fold, considering a 5-fold split.}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\textbf{Vendors} & \textbf{1$^{st}$} & \textbf{2$^{nd}$} & \textbf{3$^{rd}$} & \textbf{4$^{th}$} & \textbf{5$^{th}$} \\
		\hline
		\textbf{Cirrus} & 5 & 5 & 5 & 5 & 4 \\
		\textbf{Spectralis} & 5 & 5 & 5 & 5 & 4 \\
		\textbf{Topcon} & 4$^{a}$ + 1$^{b}$ & 4$^{a}$ + 1$^{b}$ & 4$^{a}$ & 4$^{a}$ & 4$^{a}$ \\
		\hline
		\multicolumn{6}{l}{Volumes marked with \textbf{\textit{a}} consist of 128 B-scans.} \\
		\multicolumn{6}{l}{Volumes marked with \textbf{\textit{b}} consist of 64 B-scans.} \\
	\end{tabular}
	\label{tab:FiveFoldSplit}
\end{table*}

For experiments using a binary segmentation approach, the volumes can be redistributed using the same algorithm, but with fewer constrains - a fluid-specific 5-fold split. In this case, the folds are created based only on the vendor and amount of the target fluid, thus eliminating the restrictions imposed by the quantities of the other two fluids. Nevertheless, the volumes that are in the previously defined reserved fold must not be used in either training in validation.
\par
For the experiments related with inter-slice generation, the 5-fold split of the data was not done by considering the quantity of fluid in each fold. Since the test volumes of the RETOUCH dataset were used in this experiment and fluid masks are not available, the quantity of fluid in each test volume is unknown. Please note that, for comparison purposes, one of the folds in this 5-fold split is the one reserved in the multi-class segmentation split for testing.
\par
The split was performed by taking into consideration solely the number of slices per device. In these experiments, the characteristics of each device are important, since each device has a specific inter-slice distance. This distance varies even across devices from the same vendor and is an important factor in image generation.
\par
Considering both training and testing volumes of the RETOUCH dataset, there are 38 Cirrus, 38 Spectralis, 13 Topcon T-1000, and 23 Topcon T-2000 (two of which with 64 slices). The fold reserved in the multi-class segmentation task for testing is composed of the following volumes: 4 Cirrus, 5 Spectralis, 3 Topcon T-1000, and 2 Topcon T-2000 (one of which with 64 slices). The volumes remaining for the four folds used in the generation task are distributed as shown in Table \ref{tab:FourFoldSplit}.

\begin{table*}[!ht]
	\setlength{\tabcolsep}{6pt}
	\renewcommand{\arraystretch}{1.3}
	\caption{Device-wise distribution of OCT volumes across the four folds used for training and validation in OCT slice synthesis.}
	\centering
	\begin{tabular}{|c|c|c|c|c|c}
		\cline{1-5}
		\textbf{Devices} & \textbf{1$^{st}$} & \textbf{2$^{nd}$} & \textbf{3$^{rd}$} & \textbf{4$^{th}$} & \\
		\cline{1-5}
		\textbf{Cirrus} & 9 & 8 & 9 & 8 & \\
		\textbf{Spectralis} & 9 & 8 & 9 & 8 & \\
		\textbf{T-1000} & 3 & 3 & 2 & 3 & \\
		\textbf{T-2000} & 4 & 5 & 5 & 5 & \\
		\textbf{T-2000$^{b}$} & 1 & 0 & 0 & 0 & \\
		\cline{1-5}
		\multicolumn{6}{l}{Volumes marked with \textbf{\textit{b}} consist of 64 B-scans.} \\
	\end{tabular}
	\label{tab:FourFoldSplit}
\end{table*}
	
Since the partition is not constrained by the quantity of fluid in each volume, it is possible to compute the optimal partition by iterating through all the possible combinations. In each combination, the standard deviation of the total number of B-scans in each fold is calculated. The combination with the smallest deviation was used. Similar to what was done in the fluid segmentation task, three folds were used in training while one was used in validation.

\section{Experiment 1 - Multi-class Fluid Segmentation using a single U-Net}\label{Experiment1}

In the first experiment, the base U-Net model was trained to perform 2D multi-class segmentation of the retinal fluids in OCT scans.
\par
This was the most extensive set of experiments, where many variables were tested. Different patch shapes, transformations, and hyperparameters were explored, until the best training settings were determined. The best settings were then used in Experiment 2 (section \ref{Experiment2}). All the experiments were conducted using the Adam optimizer \parencite{Kingma2015} with a learning rate of $2 \times 10^{-5}$.
\par
In each epoch, the model was trained on three folds and validated on one. The performance of the model in the validation fold allowed an insight into how the model was learning. Therefore, the instance of the model that achieved the lowest loss on validation data was saved, as this typically indicates the best generalization performance on unseen data. Also, when the model was no longer improving, training could be stopped, saving computational resources.

\subsection{Experiment 1.1 - Random Patch Extraction}
In Experiment 1.1, the patches, of size 256 $\times$ 128, were extracted randomly, following the same procedure as implemented by \textcite{Tennakoon2018}, explained in the previous chapter. For this reason, two sets of four training runs were performed, considering the 4-fold split mentioned in section \ref{CrossValidation}. In both sets, all conditions were kept identical, with the only differences being caused by the random extraction of training patches. This setup was designed to evaluate how the random nature of the patch extraction affected the model's performance. 
\par
The model was trained for 100 epochs with a batch size of 32, with no early stopping. The input patches were transformed by a rotation between 0 and 10 degrees, and horizontal flipping. 

\subsection{Experiment 1.2 - Large Patch Extraction}
In this experiment, the patch size was changed from the 256 $\times$ 128 pixels used in Experiment 1.1 to 496 $\times$ 512 pixels and was no longer extracted vertically. By using these dimensions, the model receives a larger context of the B-scan as input, allowing it to learn the anatomical references that characterize and limit the fluids.
\par
Since larger images were loaded to the model, the batch size had to be changed from the usual 32 to 16, due to memory constrains. Nevertheless, the model was trained for 100 epochs while using the same transformations as in Experiment 1.1.

\subsection{Experiment 1.3 - Vertical Patch Extraction}
In Experiment 1.3, all the images were initially resized from their original dimensions to 496 $\times$ 512 pixels, which was the shape of the smaller images in the dataset. Then, vertical patches were extracted from each B-scan. The number of patches extracted was changed, varying between four, seven, and thirteen. Regarding the transformations applied, all the models were trained with horizontal flipping and multiple rotations were tested.
\par
When using four vertical patches, the model was trained both for 100 and 200 epochs, maintaining a batch size of 32 and a maximum rotation of $10^{\circ}$, without early stopping. 
\par
Then, the model was trained using the sets of seven and thirteen patches on the best- and worse-performing folds from the four-patch setup, with early stopping applied if the validation loss did not improve within 25 epochs after reaching its minimum. This stopping criteria was only applied after the model trained for 25 epochs. This approach was adopted because the model trained much faster when using seven and thirteen patches per B-scan, due to the increased number of images processed per epoch. Henceforth, it also required more computational power, which further motivated the use of early stopping.
\par
Using seven vertical patches per image, which was the number of patches that performed best, three different rotation settings were tested: no rotation, maximum rotation of $5^{\circ}$, and maximum rotation of $10^{\circ}$. These values were tested for a better understanding of how the rotation of the image affects the segmentation and the model's understanding of anatomic references. The models where rotation was applied were trained on a minimum of 100 epochs, after which a patience of 25 epochs was applied. Therefore, if after 100 epochs the model did not improve its validation loss for 25 consecutive epochs, training would be interrupted. The models trained without rotation converged much faster and, for that reason, the minimum number of epochs used was 25, while still keeping the same patience. All models were trained for up to 200 epochs.
\par
Lastly, the model was trained using four patches and a maximum rotation of $5^{\circ}$, using the same early stopping criteria as in the last seven patches runs. This allowed for one last comparison between the two number of patches used in training, under the same conditions. The best model between those trained with four patches and those trained with seven patches using this rotation was selected to infer on the reserved test fold and in the CHUSJ dataset.

\section{Experiment 2 - Multi-class Fluid Segmentation using Three Separate U-Net models}\label{Experiment2}

The second experiment also involved multi-class segmentation of the retinal fluids. In contrast with the first experiment, where the segmentation was done using a single U-Net, three binary U-Nets were used in this experiment, with one model for IRF, one for SRF, and one for PED.
\par
All the models were trained with seven vertical patches extracted from each B-scan, on a minimum of 100 epochs, after which a patience of 25 epochs was applied - similar to what was done in the last runs of Experiment 1 (section \ref{Experiment1}). Similarly, the random transformations applied to the images consisted of horizontal flipping and a maximum rotation of $5^{\circ}$. Two losses were used in the training of these models: the loss used in the multi-class experiments and the balanced cross-entropy loss.

\subsection{Experiment 2.1 - Multi-class Segmentation Loss}

When using the loss from Experiment 1 (section \ref{Experiment1}), each model was trained on two different splits: the split used in the multi-class segmentation experiments and a split created specifically for the segmentation of the fluid that was being segmented. All the remaining conditions were equal.

\subsection{Experiment 2.2 - Balanced Cross-entropy Loss}

The balanced cross-entropy loss was tested on the best-performing folds of the multi-class and IRF splits, for the segmentation of this fluid, in the same conditions. However, since the results were much worse than those obtained with the initial loss, no more folds or fluids were tested under these conditions.

\section{Experiment 3 - Intermediate Slices Synthesis Using a GAN}
In the first intermediate slice synthesis experiment, the GAN developed by \textcite{Tran2020} was used in the generation of intermediate slices. The GAN was trained for 250 epochs, using a batch size of 32. The generator's learning rate was $2 \times 10^{-5}$, while the discriminator's was $2 \times 10^{-6}$. The selected optimizer for both networks was Adam, with $\beta_{1}=0.5$ and $\beta_{2}=0.999$.
\par
In every run, the generator model was saved every 10 epochs. Of the saved models, the one that obtained the minimal adversarial loss was selected for evaluation. Since this loss is perceptual, the model that performs the best usually generates images that look more real.

\section{Experiment 4 - Intermediate Slices Synthesis Using a U-Net}
In the second experiment, a U-Net was selected to generate the intermediate slice between a pair of two known slices. 
\par
While in the previous experiment the model was trained with patches of size 64 $\times$ 64 pixels, this model was trained with the full images, which were resized to 496 $\times$ 512 pixels. Since this requires a larger use of memory, the batch size was changed from 32 to 8.
\par
The model was trained for up to 200 epochs with a minimum of 100, after which a patience of 25 epochs was applied. The optimizer used was Adam with a learning rate of $2 \times 10^{-4}$.

\section{Experiment 5 - Fluid Volume Estimation Using Predicted Masks in Real OCT Volumes}

In this experiment, the fluid volumes were calculated for the OCT volumes without generated slices. Two volumes were calculated for each OCT volume: one using the GT masks in the RETOUCH dataset and one using the masks predicted by the best segmentation model, using the equations described in the previous chapter. The results from this experiment allow comparison with values obtained in the subsequent experiment, which used slice generation.

\section{Experiment 6 - Fluid Volume Estimation Using Predicted Masks in Generated and Super-resolved OCT Volumes}

This experiment involved estimating fluid volume in OCT scans containing generated images and the model used for segmentation was the same as in the previous experiment. This model inferred the segmentation masks on a fake OCT volume, where the all the real OCT B-scans, except the first and the last from each volume, were substituted with the B-scans generated using the GAN. The segmentation model was also used in the prediction of masks in super-resolved OCT volumes. These volumes had a generated slice between every pair of known slices.
\par
From the predicted fluid masks, the fluid volumes were estimated using the equation explained in the previous chapter, and compared between each other and with the values obtained in the previous experiment.
\par
Table \ref{tab:ExperimentsSummary} provides a summary of the experiments performed in this dissertation is shown, allowing for easier reference and comparison.

\begin{table}[H]
	\centering
	\caption{Summary of the experiments performed in this dissertation.}
	\begin{tabular}{|p{7cm}|p{7cm}|}
		\hline
		\textbf{Experiment} & \textbf{Description} \\
		\hline
		\textbf{Experiment 1 - Fluid Segmentation with Multi-class U-Net} &
		\textbf{1.1} – Trained with patches of size 256 $\times$ 128 pixels randomly extracted from the ROI. \newline
		\textbf{1.2} – Trained with large patches of size 496 $\times$ 512 pixels. \newline
		\textbf{1.3} – Trained with a varying number of vertical patches (four, seven, or thirteen) of size 496 $\times$ 128 pixels, extracted from B-scans resized to 496 $\times$ 512 pixels. \\
		\hline
		\textbf{Experiment 2 - Fluid Segmentation with Binary U-Net} & \textbf{2.1} – Trained with the same loss as in Experiment 1, using two different data partitions. \newline
		\textbf{2.2} – Trained with the balanced cross-entropy loss. \\
		\hline
		\textbf{Experiment 3 - Synthesis of Intermediate Slices using a GAN} &
		\textbf{3} – Trained a GAN to generate a fake B-scan between a pair of two known B-scans. \\
		\hline
		\textbf{Experiment 3 - Synthesis of Intermediate Slices using a U-Net} &
		\textbf{4} – Trained a U-Net to generate a fake B-scan between a pair of two known B-scans. \\
		\hline
		\textbf{Experiment 5 - Fluid Volume Estimation in Real OCT Volumes} &
		\textbf{5} – Estimated fluid volumes using the GT and the fluid masks predicted by the segmentation model. \\
		\hline
		\textbf{Experiment 6 - Fluid Volume Estimation in Super-resolved OCT Volumes} &
		\textbf{6} – Estimated fluid volumes for generated and super-resolved OCT volumes, synthesized by the GAN, using the masks predicted by the segmentation model. \\
		\hline
	\end{tabular}
	\label{tab:ExperimentsSummary}
\end{table}
