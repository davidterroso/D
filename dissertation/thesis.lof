\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces OCT B-scans (A), when taken at a fixed distance along the azimuthal axis, form a volume of the posterior segment of the eye (B) \blx@tocontentsinit {0}\parencite {Jain2010}.\relax }}{2}{figure.caption.9}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces The three distinct fluid types on an OCT B-scan: IRF in red, SRF in green, and PED in blue \blx@tocontentsinit {0}\cite {Bogunovic2019a}.\relax }}{3}{figure.caption.10}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces OCT scan of the retinal layers \blx@tocontentsinit {0}\cite {Almonte2020}.\relax }}{3}{figure.caption.11}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Grouping of the articles included in the literature review.\relax }}{6}{figure.caption.12}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a CNN architecture used in fluid binary segmentation. Image A depicts the neural network architecture. B shows the used multi-scale block, while C and D exhibit the residual convolutional blocks \blx@tocontentsinit {0}\parencite {Guo2020}.\relax }}{7}{figure.caption.13}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of a framework that includes delimitation of the retinal layer and a relative distance map (left side). The generated map is included in the segmentation network (denominated ICAF-Net, by the authors) \blx@tocontentsinit {0}\parencite {Tang2022}.\relax }}{9}{figure.caption.14}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces \blx@tocontentsinit {0}\textcite {Lopez2023} training process.\relax }}{10}{figure.caption.15}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Framework developed by \blx@tocontentsinit {0}\textcite {Xia2021}.\relax }}{12}{figure.caption.16}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Architecture of the method developed by \blx@tocontentsinit {0}\textcite {Zhang2024}.\relax }}{13}{figure.caption.17}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Pipeline of the methodology utilized by \blx@tocontentsinit {0}\textcite {Fang2022}.\relax }}{14}{figure.caption.18}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Pipeline that describes the RIFE framework. The student model attempts to generate the intermediate frame, while the teacher refines the frame generated by the student so that it looks more similar to the middle frame. The results from both networks are evaluated on the reconstruction loss \blx@tocontentsinit {0}\parencite {Huang2022}.\relax }}{16}{figure.caption.19}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Pipeline representing the framework developed by \blx@tocontentsinit {0}\textcite {Tran2020}. The generator that generates the intermediate frame is represented by $G$, while its discriminator is labeled $D$. The pix2pix generator is denoted by $G\_RN$ and the discriminator is represented by $D\_RN$. $x_{n-1}$ and $x_{n+1}$ respectively represent the previous and following frames of the one that is being generated, $x_{n}$. $y_{n}$ is the image generated by the first generator, while $y'_{n}$ is the image refined by the pix2pix network \blx@tocontentsinit {0}\parencite {Tran2020}.\relax }}{17}{figure.caption.20}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces U-Net architecture \blx@tocontentsinit {0}\cite {Ronneberger2015}.\relax }}{22}{figure.caption.24}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Cirrus B-scan (left), fluid masks overlay (middle) with IRF in red, SRF in green, and PED in blue, and the ROI mask overlaid in purple (right). The red bounding box signals a possible 256 $\times $ 128 patch that could be extracted.\relax }}{24}{figure.caption.26}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Cirrus B-scan and its respective three patches of shape 496 $\times $ 512.\relax }}{25}{figure.caption.28}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces B-scan of the retinal layers in different patients, using Cirrus (left) and Spectralis (right) devices. In Cirrus, the retinal layers appear much larger than in Spectralis.\relax }}{25}{figure.caption.30}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Four vertical patches of shape 496 $\times $ 128 extracted from a Cirrus B-scan.\relax }}{26}{figure.caption.31}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Seven vertical patches of shape 496 $\times $ 128 extracted from a Cirrus B-scan.\relax }}{26}{figure.caption.32}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Thirteen vertical patches of shape 496 $\times $ 128 extracted from a Cirrus B-scan.\relax }}{27}{figure.caption.33}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Scheme explaining the input data of the generative models. Each frame refers to B-scan from an OCT volume. Extracted from \blx@tocontentsinit {0}\textcite {Tran2020}.\relax }}{29}{figure.caption.34}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Example of a GAN framework, where $\mathcal {D}$ is the discriminator and $\mathcal {G}$ is the generator \blx@tocontentsinit {0}\cite {Creswell2018}.\relax }}{30}{figure.caption.35}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Patches with shape 64 $\times $ 64 extracted from a Cirrus B-scan which was resized to 496 $\times $ 512.\relax }}{31}{figure.caption.36}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Architecture of the generator used in the GAN. It has a contracting and an expanding path, making it a U-Net like network \blx@tocontentsinit {0}\parencite {Tran2020}.\relax }}{32}{figure.caption.37}%
\addvspace {10\p@ }
\addvspace {10\p@ }
