\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces OCT B-scans (A), when taken at a fixed distance along the azimuthal axis, form a volume of the posterior segment of the eye (B) \blx@tocontentsinit {0}\parencite {Jain2010}.\relax }}{2}{figure.caption.9}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces The three distinct fluid types on an OCT B-scan: IRF in red, SRF in green, and PED in blue \blx@tocontentsinit {0}\cite {Bogunovic2019a}.\relax }}{3}{figure.caption.10}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces OCT scan of the retinal layers \blx@tocontentsinit {0}\cite {Almonte2020}.\relax }}{3}{figure.caption.11}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Grouping of the articles included in the literature review.\relax }}{6}{figure.caption.12}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a CNN architecture used in fluid binary segmentation. Image A depicts the neural network architecture. B shows the used multi-scale block, while C and D exhibit the residual convolutional blocks \blx@tocontentsinit {0}\parencite {Guo2020}.\relax }}{7}{figure.caption.13}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of a framework that includes delimitation of the retinal layer and a relative distance map (left side). The generated map is included in the segmentation network (denominated ICAF-Net, by the authors) \blx@tocontentsinit {0}\parencite {Tang2022}.\relax }}{9}{figure.caption.14}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces \blx@tocontentsinit {0}\textcite {Lopez2023} training process.\relax }}{10}{figure.caption.15}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Framework developed by \blx@tocontentsinit {0}\textcite {Xia2021}.\relax }}{12}{figure.caption.16}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Architecture of the method developed by \blx@tocontentsinit {0}\textcite {Zhang2024}.\relax }}{13}{figure.caption.17}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Pipeline of the methodology utilized by \blx@tocontentsinit {0}\textcite {Fang2022}.\relax }}{14}{figure.caption.18}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Pipeline that describes the RIFE framework. The student model attempts to generate the intermediate frame, while the teacher refines the frame generated by the student so that it looks more similar to the middle frame. The results from both networks are evaluated on the reconstruction loss \blx@tocontentsinit {0}\parencite {Huang2022}.\relax }}{16}{figure.caption.19}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Pipeline representing the framework developed by \blx@tocontentsinit {0}\textcite {Tran2020}. The generator that generates the intermediate frame is represented by $G$, while its discriminator is labeled $D$. The pix2pix generator is denoted by $G\_RN$ and the discriminator is represented by $D\_RN$. $x_{n-1}$ and $x_{n+1}$ respectively represent the previous and following frames of the one that is being generated, $x_{n}$. $y_{n}$ is the image generated by the first generator, while $y'_{n}$ is the image refined by the pix2pix network \blx@tocontentsinit {0}\parencite {Tran2020}.\relax }}{17}{figure.caption.20}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Three different B-scans with different dimensions (496 $\times $ 1024, 496 $\times $ 768, and 496 $\times $ 512, respectively) from the CHUSJ dataset. As shown in the scale at the bottom left of each B-scan, the resolutions are also differ depending on the slice.\relax }}{20}{figure.caption.22}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Three B-scans with characteristics different from those in RETOUCH. The left scan shows definition on the choroid, while the middle and right scan present an odd orientation and significant noise.\relax }}{20}{figure.caption.23}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Significantly different segmentations (middle images) of the same B-scan (left image) by different evaluators. The mask seen in cyan in the last image represents the final fluid regions when considering both evaluations \blx@tocontentsinit {0}\parencite {Bogunovic2019b}.\relax }}{21}{figure.caption.24}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Visually similar PED regions are segmented in one dataset but not on the other. This ambiguous segmentation can translate to worse performances in the model.\relax }}{21}{figure.caption.25}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces U-Net architecture \blx@tocontentsinit {0}\cite {Ronneberger2015}.\relax }}{24}{figure.caption.28}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Cirrus B-scan (left), fluid masks overlay (middle) with IRF in red, SRF in green, and PED in blue, and the ROI mask overlaid in purple (right). The red bounding box signals a possible 256 $\times $ 128 patch that could be extracted.\relax }}{26}{figure.caption.30}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Cirrus B-scan and its respective three patches of shape 496 $\times $ 512.\relax }}{27}{figure.caption.32}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces B-scan of the retinal layers in different patients, using Cirrus (left) and Spectralis (right) devices. In Cirrus, the retinal layers appear much larger than in Spectralis.\relax }}{28}{figure.caption.34}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Four vertical patches of shape 496 $\times $ 128 extracted from a Cirrus B-scan.\relax }}{28}{figure.caption.35}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Seven vertical patches of shape 496 $\times $ 128 extracted from a Cirrus B-scan.\relax }}{28}{figure.caption.36}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Thirteen vertical patches of shape 496 $\times $ 128 extracted from a Cirrus B-scan.\relax }}{29}{figure.caption.37}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Scheme explaining the input data of the generative models. Each frame refers to B-scan from an OCT volume. Extracted from \blx@tocontentsinit {0}\textcite {Tran2020}.\relax }}{31}{figure.caption.38}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces Example of a GAN framework, where $\mathcal {D}$ is the discriminator and $\mathcal {G}$ is the generator \blx@tocontentsinit {0}\cite {Creswell2018}.\relax }}{33}{figure.caption.39}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Patches with shape 64 $\times $ 64 extracted from a Cirrus B-scan which was resized to 496 $\times $ 512.\relax }}{33}{figure.caption.40}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Architecture of the generator used in the GAN. It has a contracting and an expanding path, making it a U-Net like network \blx@tocontentsinit {0}\parencite {Tran2020}.\relax }}{34}{figure.caption.41}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example of a patch extracted from a Cirrus OCT volume used in Experiment 1.1. In this patch, while the background is noticeable due to its darker shade, the choroid is harder to be identified by an observer (or a model) due to the lack of context.\relax }}{41}{figure.caption.44}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Example of a poor segmentation made by the model trained in Run 1 (right). In the left, the GT mask for the same image is shown.\relax }}{42}{figure.caption.45}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Example of the segmentation done by the model trained in Run 9 (right) and its respective GT mask (left). The B-scan segmented is the same as in Figure \ref {fig:Experiment11Segmentation}.\relax }}{43}{figure.caption.47}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Example of the segmentation done by the model trained in Run 12 (right) and its respective GT mask (left). It is noticeable that the model confuses the choroid with the retina, as segmentation of IRF and PED is performed in the choroid.\relax }}{43}{figure.caption.48}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Training and validation losses in Run 13 (left) and Run 17 (right). Despite reaching the validation loss minimum in a similar number of epochs and having comparable training and validation loss curves, the performance is really different in Table \ref {tab:Experiment1.3FourPatches}.\relax }}{45}{figure.caption.50}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Predicted masks by the models trained on Run 16 (middle) and Run 20 (right) and their respective GT (left).\relax }}{46}{figure.caption.51}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Training and validation losses for models validated on fold 2. The curves on the left are from the model trained on Run 17 with four patches, while the middle curves are from the model trained on Run 21, with seven patches. The curves on the right are from the model trained on Run 23, with thirteen patches.\relax }}{47}{figure.caption.53}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Segmentation errors in Cirrus B-scans. The GT fluid masks, seen on the left, show a large region of PED fluid. Meanwhile, the predictions made by the models trained in Run 21 and 23, which respectively correspond to the B-scans in the middle and right, classify the center of this region as IRF.\relax }}{48}{figure.caption.54}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Transformations applied to a vertical patch of a Cirrus B-scan. The original vertical patch (left) can be rotated a maximum of $10^{\circ }$, a transformation that is shown in the middle image. The image on the right represents the combination of a $10^{\circ }$ rotation and an horizontal flip. It is seen that the rotation transform pads a significant portion of the image, reducing the information in the input.\relax }}{48}{figure.caption.55}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Example of two B-scans in which the retina is oriented differently. The retina present in the right image is significantly more inclined. Both B-scans were obtained using a Cirrus device and do not present fluid.\relax }}{50}{figure.caption.57}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Segmentation errors in Cirrus B-scans when trained without random rotations, in the same B-scan as in Figure \ref {fig:CirrusSegmentationErrors}. In the left, the GT masks are shown, while in the right the predicted masks are exhibited.\relax }}{50}{figure.caption.58}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces Predictions by the models trained using $5^{\circ }$ (middle image) and $10^{\circ }$ (right image) rotations, compared with the respective GT (left image).\relax }}{51}{figure.caption.61}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces Predictions by the model trained on Run 32 in unseen Cirrus volumes of fold 1.\relax }}{54}{figure.caption.64}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces Predictions by the model trained on Run 32 in unseen Spectralis volumes of fold 1.\relax }}{54}{figure.caption.65}%
\contentsline {figure}{\numberline {4.15}{\ignorespaces Predictions by the model trained on Run 32 in unseen Topcon volumes of fold 1.\relax }}{55}{figure.caption.66}%
\contentsline {figure}{\numberline {4.16}{\ignorespaces Predictions (right) performed by the binary IRF segmentation model and their respective GT (left). The prediction represented in the top show an example of an accurate IRF segmentation, while the bottom prediction reveals an oversegmentation in a slice that does not contain fluid.\relax }}{57}{figure.caption.68}%
\contentsline {figure}{\numberline {4.17}{\ignorespaces Predictions (right) performed by the binary PED segmentation model and their respective GT (left). In top right, the model predicted PED fluid in a region where it does not exist. The bottom images show the undersegmentation of the model trained in Run 59. While this model is capable of detecting the fluid location, it fails to segment its entirety.\relax }}{60}{figure.caption.71}%
\contentsline {figure}{\numberline {4.18}{\ignorespaces Comparison between the priority (left) and probability (right) merging approach.\relax }}{61}{figure.caption.72}%
\contentsline {figure}{\numberline {4.19}{\ignorespaces Predictions by the models trained on Run 42, 52, and 59 in unseen Cirrus volumes of fold 1 (last row), contrasting with predictions made by the multi-class model from Experiment 1.\relax }}{63}{figure.caption.74}%
\contentsline {figure}{\numberline {4.20}{\ignorespaces Predictions by the models trained on Run 42, 52, and 59 in unseen Spectralis volumes of fold 1 (last row), contrasting with predictions made by the multi-class model from Experiment 1.\relax }}{64}{figure.caption.75}%
\contentsline {figure}{\numberline {4.21}{\ignorespaces Predictions by the models trained on Run 42, 52, and 59 in unseen Topcon volumes of fold 1 (last row), contrasting with predictions made by the multi-class model from Experiment 1.\relax }}{64}{figure.caption.76}%
\contentsline {figure}{\numberline {4.22}{\ignorespaces Small oversegmentation performed in a Spectralis B-scan. This type of predictions appear commonly across multiple B-scans.\relax }}{66}{figure.caption.78}%
\contentsline {figure}{\numberline {4.23}{\ignorespaces Cirrus IRF segmentation performed by a model trained using BCE shown on the right, compared to its GT on the left. While this example has a decent segmentation, significant oversegmentation is seen on the top left of the image.\relax }}{66}{figure.caption.79}%
\contentsline {figure}{\numberline {4.24}{\ignorespaces SRF and PED segmentation in two B-scans from CHUSJ. The regions segmented by the model as PED could also be considered fluid, depending on the criteria applied.\relax }}{72}{figure.caption.84}%
\contentsline {figure}{\numberline {4.25}{\ignorespaces SRF and PED segmentation (right) in a B-scan from CHUSJ, compared to its GT (left). This shows the tendency to oversegmentation by the model.\relax }}{72}{figure.caption.85}%
\contentsline {figure}{\numberline {4.26}{\ignorespaces Segmentation of IRF regions (right) compared to its respective GT (left). The prediction of fluid regions in the choroid is also noticeable.\relax }}{73}{figure.caption.86}%
\contentsline {figure}{\numberline {4.27}{\ignorespaces Segmentation of multiple fluids in the choroid region of the B-scans. This is performed often, significantly reducing the Dice coefficients seen in Table \ref {tab:CHUSJSegmentationResults}.\relax }}{74}{figure.caption.87}%
\contentsline {figure}{\numberline {4.28}{\ignorespaces Fluid segmentations performed by the multi-class model in noisy B-scans from the CHUSJ dataset.\relax }}{75}{figure.caption.88}%
\addvspace {10\p@ }
\addvspace {10\p@ }
